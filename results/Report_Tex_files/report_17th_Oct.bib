@article{BWA,
author = {Li, Heng and Durbin, Richard}, 
title = {Fast and accurate short read alignment with Burrows–Wheeler transform},
volume = {25}, 
number = {14}, 
pages = {1754-1760}, 
year = {2009}, 
doi = {10.1093/bioinformatics/btp324}, 
abstract ={Motivation: The enormous amount of short reads generated by the new DNA sequencing technologies call for the development of fast and accurate read alignment programs. A first generation of hash table-based methods has been developed, including MAQ, which is accurate, feature rich and fast enough to align short reads from a single individual. However, MAQ does not support gapped alignment for single-end reads, which makes it unsuitable for alignment of longer reads where indels may occur frequently. The speed of MAQ is also a concern when the alignment is scaled up to the resequencing of hundreds of individuals.Results: We implemented Burrows-Wheeler Alignment tool (BWA), a new read alignment package that is based on backward search with Burrows–Wheeler Transform (BWT), to efficiently align short sequencing reads against a large reference sequence such as the human genome, allowing mismatches and gaps. BWA supports both base space reads, e.g. from Illumina sequencing machines, and color space reads from AB SOLiD machines. Evaluations on both simulated and real data suggest that BWA is ∼10–20× faster than MAQ, while achieving similar accuracy. In addition, BWA outputs alignment in the new standard SAM (Sequence Alignment/Map) format. Variant calling and other downstream analyses after the alignment can be achieved with the open source SAMtools software package.Availability: http://maq.sourceforge.netContact: rd@sanger.ac.uk}, 
URL = {http://bioinformatics.oxfordjournals.org/content/25/14/1754.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/25/14/1754.full.pdf+html}, 
journal = {Bioinformatics} 
}


@article{gatk1,
    abstract = {{Next-generation DNA sequencing (NGS) projects, such as the 1000 Genomes Project, are already revolutionizing our understanding of genetic variation among individuals. However, the massive data sets generated by NGS--the 1000 Genome pilot alone includes nearly five terabases--make writing feature-rich, efficient, and robust analysis tools difficult for even computationally sophisticated individuals. Indeed, many professionals are limited in the scope and the ease with which they can answer scientific questions by the complexity of accessing and manipulating the data produced by these machines. Here, we discuss our Genome Analysis Toolkit (GATK), a structured programming framework designed to ease the development of efficient and robust analysis tools for next-generation DNA sequencers using the functional programming philosophy of MapReduce. The GATK provides a small but rich set of data access patterns that encompass the majority of analysis tool needs. Separating specific analysis calculations from common data management infrastructure enables us to optimize the GATK framework for correctness, stability, and CPU and memory efficiency and to enable distributed and shared memory parallelization. We highlight the capabilities of the GATK by describing the implementation and application of robust, scale-tolerant tools like coverage calculators and single nucleotide polymorphism (SNP) calling. We conclude that the GATK programming framework enables developers and analysts to quickly and easily write efficient and robust NGS tools, many of which have already been incorporated into large-scale sequencing projects like the 1000 Genomes Project and The Cancer Genome Atlas.}},
    author = {McKenna, Aaron and Hanna, Matthew and Banks, Eric and Sivachenko, Andrey and Cibulskis, Kristian and Kernytsky, Andrew and Garimella, Kiran and Altshuler, David and Gabriel, Stacey and Daly, Mark and DePristo, Mark A.},
    citeulike-article-id = {7515828},
    citeulike-linkout-0 = {http://dx.doi.org/10.1101/gr.107524.110},
    citeulike-linkout-1 = {http://genome.cshlp.org/content/early/2010/08/04/gr.107524.110.abstract},
    citeulike-linkout-2 = {http://genome.cshlp.org/content/early/2010/08/04/gr.107524.110.full.pdf},
    citeulike-linkout-3 = {http://genome.cshlp.org/cgi/content/abstract/20/9/1297},
    citeulike-linkout-4 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2928508/},
    citeulike-linkout-5 = {http://view.ncbi.nlm.nih.gov/pubmed/20644199},
    citeulike-linkout-6 = {http://www.hubmed.org/display.cgi?uids=20644199},
    day = {01},
    doi = {10.1101/gr.107524.110},
    issn = {1549-5469},
    journal = {Genome research},
    keywords = {snp, variant\_calling},
    month = sep,
    number = {9},
    pages = {1297--1303},
    pmcid = {PMC2928508},
    pmid = {20644199},
    posted-at = {2012-05-18 09:22:07},
    priority = {2},
    publisher = {Cold Spring Harbor Laboratory Press},
    title = {{The Genome Analysis Toolkit: a MapReduce framework for analyzing next-generation DNA sequencing data.}},
    url = {http://dx.doi.org/10.1101/gr.107524.110},
    volume = {20},
    year = {2010}
}

@article{swegen,
  title={SweGen: a whole-genome data resource of genetic variability in a cross-section of the Swedish population.},
  author={Ameur, Adam and Dahlberg, Johan and Olason, Pall and Vezzi, Francesco and Karlsson, Robert and Martin, Marcel and Viklund, Johan and K{\"a}h{\"a}ri, Andreas Kusalananda and Lundin, P{\"a}r and Che, Huiwen and others},
  journal={European journal of human genetics: EJHG},
  year={2017}
}

@article{gatk2,
    abstract = {{Recent advances in sequencing technology make it possible to comprehensively catalog genetic variation in population samples, creating a foundation for understanding human disease, ancestry and evolution. The amounts of raw data produced are prodigious, and many computational steps are required to translate this output into high-quality variant calls. We present a unified analytic framework to discover and genotype variation among multiple samples simultaneously that achieves sensitive and specific results across five sequencing technologies and three distinct, canonical experimental designs. Our process includes (i) initial read mapping; (ii) local realignment around indels; (iii) base quality score recalibration; (iv) SNP discovery and genotyping to find all potential variants; and (v) machine learning to separate true segregating variation from machine artifacts common to next-generation sequencing technologies. We here discuss the application of these tools, instantiated in the Genome Analysis Toolkit, to deep whole-genome, whole-exome capture and multi-sample low-pass (∼4×) 1000 Genomes Project datasets.}},
    author = {DePristo, Mark A. and Banks, Eric and Poplin, Ryan and Garimella, Kiran V. and Maguire, Jared R. and Hartl, Christopher and Philippakis, Anthony A. and del Angel, Guillermo and Rivas, Manuel A. and Hanna, Matt and McKenna, Aaron and Fennell, Tim J. and Kernytsky, Andrew M. and Sivachenko, Andrey Y. and Cibulskis, Kristian and Gabriel, Stacey B. and Altshuler, David and Daly, Mark J.},
    citeulike-article-id = {9134853},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/ng.806},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/ng.806},
    citeulike-linkout-2 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3083463/},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/21478889},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=21478889},
    day = {10},
    doi = {10.1038/ng.806},
    issn = {1546-1718},
    journal = {Nature genetics},
    keywords = {methods, ngs},
    month = may,
    number = {5},
    pages = {491--498},
    pmcid = {PMC3083463},
    pmid = {21478889},
    posted-at = {2011-07-14 09:42:47},
    priority = {2},
    publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
    title = {{A framework for variation discovery and genotyping using next-generation DNA sequencing data.}},
    url = {http://dx.doi.org/10.1038/ng.806},
    volume = {43},
    year = {2011}
}


@article{li2014toward,
  title={Toward better understanding of artifacts in variant calling from high-coverage samples},
  author={Li, Heng},
  journal={Bioinformatics},
  volume={30},
  number={20},
  pages={2843--2851},
  year={2014},
  publisher={Oxford University Press}
}


@article{danecek2011variant,
  title={The variant call format and VCFtools},
  author={Danecek, Petr and Auton, Adam and Abecasis, Goncalo and Albers, Cornelis A and Banks, Eric and DePristo, Mark A and Handsaker, Robert E and Lunter, Gerton and Marth, Gabor T and Sherry, Stephen T and others},
  journal={Bioinformatics},
  volume={27},
  number={15},
  pages={2156--2158},
  year={2011},
  publisher={Oxford University Press}
}

@article{quickgo,
  title={QuickGO: a web-based tool for Gene Ontology searching},
  author={Binns, David and Dimmer, Emily and Huntley, Rachael and Barrell, Daniel and O'donovan, Claire and Apweiler, Rolf},
  journal={Bioinformatics},
  volume={25},
  number={22},
  pages={3045--3046},
  year={2009},
  publisher={Oxford University Press}
}

@ONLINE{Ohta,
author = {Ringo Oki, S; Ohta, T},
title = {ChIP-Atlas},
year = {2015  (accessed Sep20, 2017)},
url = {https://github.com/inutano/chip-atlas/}
}

@article{mora2015loop,
  title={In the loop: promoter--enhancer interactions and bioinformatics},
  author={Mora, Antonio and Sandve, Geir Kjetil and Gabrielsen, Odd Stokke and Eskeland, Ragnhild},
  journal={Briefings in bioinformatics},
  volume={17},
  number={6},
  pages={980--995},
  year={2015},
  publisher={Oxford University Press}
}

@article{grisar2011endothelial,
  title={Endothelial progenitor cells in cardiovascular disease and chronic inflammation: from biomarker to therapeutic agent},
  author={Grisar, Johannes C and Haddad, Francois and Gomari, Fatemeh A and Wu, Joseph C},
  journal={Biomarkers},
  volume={5},
  number={6},
  pages={731--744},
  year={2011},
  publisher={Future Medicine}
}
    